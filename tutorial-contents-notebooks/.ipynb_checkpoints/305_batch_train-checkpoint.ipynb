{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 305 Batch Train\n",
    "\n",
    "View more, visit my tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "My Youtube Channel: https://www.youtube.com/user/MorvanZhou\n",
    "\n",
    "Dependencies:\n",
    "* torch: 1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0f0133d770>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(1, 10, 10)\n",
    "y = torch.linspace(10, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "\n",
    "torch_dataset = Data.TensorDataset(x, y, y)    # 可以将任意数量的第0维大小相等的tensor数组传入，供DataLoader生成批处理迭代器。\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # random shuffle for training\n",
    "    num_workers=2,              # subprocesses for loading data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Step:  0 | batch x:  tensor([ 5.,  7., 10.,  3.,  4.]) | batch y:  tensor([6., 4., 1., 8., 7.]) | batch z:  tensor([6., 4., 1., 8., 7.])\n",
      "Epoch:  0 | Step:  1 | batch x:  tensor([2., 1., 8., 9., 6.]) | batch y:  tensor([ 9., 10.,  3.,  2.,  5.]) | batch z:  tensor([ 9., 10.,  3.,  2.,  5.])\n",
      "Epoch:  1 | Step:  0 | batch x:  tensor([ 4.,  6.,  7., 10.,  8.]) | batch y:  tensor([7., 5., 4., 1., 3.]) | batch z:  tensor([7., 5., 4., 1., 3.])\n",
      "Epoch:  1 | Step:  1 | batch x:  tensor([5., 3., 2., 1., 9.]) | batch y:  tensor([ 6.,  8.,  9., 10.,  2.]) | batch z:  tensor([ 6.,  8.,  9., 10.,  2.])\n",
      "Epoch:  2 | Step:  0 | batch x:  tensor([ 4.,  2.,  5.,  6., 10.]) | batch y:  tensor([7., 9., 6., 5., 1.]) | batch z:  tensor([7., 9., 6., 5., 1.])\n",
      "Epoch:  2 | Step:  1 | batch x:  tensor([3., 9., 1., 8., 7.]) | batch y:  tensor([ 8.,  2., 10.,  3.,  4.]) | batch z:  tensor([ 8.,  2., 10.,  3.,  4.])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):   # train entire dataset 3 times\n",
    "    for i, (batch_x, batch_y, batch_z) in enumerate(loader):  # for each training step\n",
    "        # train your data...\n",
    "        print('Epoch: ', epoch, '| Step: ', i, '| batch x: ',\n",
    "              batch_x, '| batch y: ', batch_y, '| batch z: ', batch_z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppose a different batch size that cannot be fully divided by the number of data entreis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Step:  0 | batch x:  tensor([ 4., 10.,  9.,  8.,  7.,  6.,  1.,  2.]) | batch y:  tensor([ 7.,  1.,  2.,  3.,  4.,  5., 10.,  9.])\n",
      "Epoch:  0 | Step:  1 | batch x:  tensor([5., 3.]) | batch y:  tensor([6., 8.])\n",
      "Epoch:  1 | Step:  0 | batch x:  tensor([9., 8., 4., 6., 5., 3., 7., 2.]) | batch y:  tensor([2., 3., 7., 5., 6., 8., 4., 9.])\n",
      "Epoch:  1 | Step:  1 | batch x:  tensor([10.,  1.]) | batch y:  tensor([ 1., 10.])\n",
      "Epoch:  2 | Step:  0 | batch x:  tensor([ 5.,  1.,  3.,  7.,  6., 10.,  9.,  8.]) | batch y:  tensor([ 6., 10.,  8.,  4.,  5.,  1.,  2.,  3.])\n",
      "Epoch:  2 | Step:  1 | batch x:  tensor([2., 4.]) | batch y:  tensor([9., 7.])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "loader = Data.DataLoader(\n",
    "    dataset=Data.TensorDataset(x, y),      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # random shuffle for training\n",
    "    num_workers=2,              # subprocesses for loading data\n",
    ")\n",
    "for epoch in range(3):   # train entire dataset 3 times\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):  # for each training step\n",
    "        # train your data...\n",
    "        print('Epoch: ', epoch, '| Step: ', step, '| batch x: ',\n",
    "              batch_x, '| batch y: ', batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
